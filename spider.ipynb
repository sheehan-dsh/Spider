{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#访问测试\n",
    "import requests\n",
    "import threading\n",
    "from bs4 import BeautifulSoup\n",
    "from multiprocessing import Pool\n",
    "url = 'http://www.google.com/'\n",
    "headers = { \"user-agent\": \"Mozilla/5.0\"}#头部\n",
    "response = requests.get(url,headers=headers)\n",
    "html = response.content\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "# print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<span id=\"mainModuleContainer_1855_1856_ctl00_ctl00_p1_f1_r2_c4_ctrl\">0.000000</span>]\n"
     ]
    }
   ],
   "source": [
    "#爬取某一页的信息\n",
    "url ='http://www.landchina.com/default.aspx?tabid=386&comname=default&wmguid=75c72564-ffd9-426a-954b-8ac2df0903b7&recorderguid=7160d5a4-cb09-4747-a9f9-253970f95606'\n",
    "headers = { 'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.90 Safari/537.36',\n",
    "            'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3',\n",
    "           'accept-language':'zh-CN,zh;q=0.9', \n",
    "           'Connection': 'keep-alive',\n",
    "           'Cookie': 'ASP.NET_SessionId=xsv3m3hk1zf55yly1qrsrdt3; Hm_lvt_83853859c7247c5b03b527894622d3fa=1563518388; security_session_verify=f97ae091cb2bc1add4f47e32edf50684; Hm_lpvt_83853859c7247c5b03b527894622d3fa=1563522325'\n",
    "          }#头部\n",
    "data = {'TAB_QuerySubmitPagerData':page}\n",
    "response = requests.post(url,data = data)\n",
    "html = response.content\n",
    "soup = BeautifulSoup(html,'lxml')\n",
    "text = soup.find_all('span',id='mainModuleContainer_1855_1856_ctl00_ctl00_p1_f1_r2_c4_ctrl')\n",
    "print(text)\n",
    " \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#遇到动态加载页面的情况可以使用POST加页码的方式\n",
    "def spider(page):\n",
    "    url ='http://www.landchina.com/default.aspx?tabid=263&wmguid=75c72564-ffd9-426a-954b-8ac2df0903b7&p=9f2c3acd-0256-4da2-a659-6949c4671a2a%3A2001-1-1%7E2013-12-31'\n",
    "    headers = { 'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.90 Safari/537.36',\n",
    "                'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3',\n",
    "               'accept-language':'zh-CN,zh;q=0.9', \n",
    "               'Connection': 'keep-alive',\n",
    "               'Cookie': 'ASP.NET_SessionId=xsv3m3hk1zf55yly1qrsrdt3; Hm_lvt_83853859c7247c5b03b527894622d3fa=1563518388; security_session_verify=f97ae091cb2bc1add4f47e32edf50684; Hm_lpvt_83853859c7247c5b03b527894622d3fa=1563522325'\n",
    "              }#头部\n",
    "    data = {'TAB_QuerySubmitPagerData':page}\n",
    "    response = requests.post(url,data = data)\n",
    "    html = response.content\n",
    "    soup = BeautifulSoup(html,'lxml')\n",
    "    text = soup.find_all('td',class_='queryCellBordy')\n",
    "    if text == [] or text == None:\n",
    "        print('error',page)\n",
    "        spider(page)\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get(soup):\n",
    "    lis = []\n",
    "    value = ['mainModuleContainer_1855_1856_ctl00_ctl00_p1_f1_r1_c2_ctrl',\n",
    "    'mainModuleContainer_1855_1856_ctl00_ctl00_p1_f1_r1_c4_ctrl',\n",
    "    'mainModuleContainer_1855_1856_ctl00_ctl00_p1_f1_r17_c2_ctrl',\n",
    "    'mainModuleContainer_1855_1856_ctl00_ctl00_p1_f1_r16_c2_ctrl',\n",
    "    'mainModuleContainer_1855_1856_ctl00_ctl00_p1_f1_r2_c2_ctrl',\n",
    "    'mainModuleContainer_1855_1856_ctl00_ctl00_p1_f1_r2_c4_ctrl',\n",
    "    'mainModuleContainer_1855_1856_ctl00_ctl00_p1_f1_r3_c2_ctrl',\n",
    "    'mainModuleContainer_1855_1856_ctl00_ctl00_p1_f1_r3_c4_ctrl',\n",
    "    'mainModuleContainer_1855_1856_ctl00_ctl00_p1_f1_r19_c2_ctrl',\n",
    "    'mainModuleContainer_1855_1856_ctl00_ctl00_p1_f1_r19_c4_ctrl',\n",
    "    'mainModuleContainer_1855_1856_ctl00_ctl00_p1_f1_r20_c2_ctrl',\n",
    "    'mainModuleContainer_1855_1856_ctl00_ctl00_p1_f1_r20_c4_ctrl',\n",
    "    'mainModuleContainer_1855_1856_ctl00_ctl00_p1_f3_r2_c1_0_ctrl',\n",
    "    'mainModuleContainer_1855_1856_ctl00_ctl00_p1_f3_r2_c2_0_ctrl',\n",
    "    'mainModuleContainer_1855_1856_ctl00_ctl00_p1_f3_r2_c3_0_ctrl'\n",
    "    'mainModuleContainer_1855_1856_ctl00_ctl00_p1_f3_r2_c4_0',\n",
    "    'mainModuleContainer_1855_1856_ctl00_ctl00_p1_f1_r9_c2_ctrl',\n",
    "    'mainModuleContainer_1855_1856_ctl00_ctl00_p1_f2_r1_c2_ctrl',\n",
    "    'mainModuleContainer_1855_1856_ctl00_ctl00_p1_f2_r1_c4_ctrl',\n",
    "    'mainModuleContainer_1855_1856_ctl00_ctl00_p1_f1_r21_c4_ctrl',\n",
    "    'mainModuleContainer_1855_1856_ctl00_ctl00_p1_f1_r22_c2_ctrl',\n",
    "    'mainModuleContainer_1855_1856_ctl00_ctl00_p1_f1_r22_c4_ctrl',\n",
    "    'mainModuleContainer_1855_1856_ctl00_ctl00_p1_f1_r10_c2_ctrl',\n",
    "    'mainModuleContainer_1855_1856_ctl00_ctl00_p1_f1_r10_c4_ctrl',\n",
    "    'mainModuleContainer_1855_1856_ctl00_ctl00_p1_f1_r14_c2_ctrl',\n",
    "    'mainModuleContainer_1855_1856_ctl00_ctl00_p1_f1_r14_c4_ctrl']\n",
    "    for val in value:\n",
    "        try:\n",
    "            span  = soup.find('span',id=val)\n",
    "            span.string\n",
    "        except:\n",
    "            lis.append(None)\n",
    "        else:\n",
    "            lis.append(span.string)\n",
    "    return lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "file = open('output.csv','a',newline = '')\n",
    "# csv_write = csv.writer(file)\n",
    "# headers = { 'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.90 Safari/537.36',\n",
    "#                 'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3',\n",
    "#                'accept-language':'zh-CN,zh;q=0.9', \n",
    "#                'Connection': 'keep-alive',\n",
    "#                'Cookie': 'ASP.NET_SessionId=xsv3m3hk1zf55yly1qrsrdt3; Hm_lvt_83853859c7247c5b03b527894622d3fa=1563518388; security_session_verify=f97ae091cb2bc1add4f47e32edf50684; Hm_lpvt_83853859c7247c5b03b527894622d3fa=1563522325'\n",
    "#               }#头部\n",
    "# http = 'http://www.landchina.com/'\n",
    "# label =['从属页码','网址','标题','行政区','电子监管号','项目名称','项目位置','面积（公顷）','土地来源','土地用途','供地方式','土地使用年限','行业分类','土地级别','成交价格（万元）','分期支付约定:支付期号','分期支付约定:约定支付日期','分期支付约定:约定支付金额（万元)','备注','土地使用权人','约定容积率下限','约定容积率上限','约定交地时间','约定开工时间','约定竣工时间','实际开工时间','实际竣工时间','批准单位','合同签订日期']\n",
    "# csv_write.writerow(label)\n",
    "# for i in range(1):\n",
    "#     page = i + 1\n",
    "#     text = spider(page)\n",
    "#     for td in text:\n",
    "#         if td.a != None:\n",
    "#             lis = []\n",
    "#             lis.append(page)\n",
    "#             url_link = http + td.a['href']\n",
    "#             title = td.a.string\n",
    "#             lis.append(url_link)\n",
    "#             lis.append(title)\n",
    "#             response = requests.get(url_link,headers = headers)\n",
    "#             html = response.content\n",
    "#             soup = BeautifulSoup(html,'html.parser')\n",
    "#             message = get(soup)\n",
    "#             lis = lis + message\n",
    "#             lis= [None if x=='\\xa0' else x for x in lis]\n",
    "#             csv_write.writerow(lis)\n",
    "# file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义爬取网页和头部\n",
    "url_1 = 'https://www.ituba.cc/meinvtupian/p'\n",
    "url_2 = '.html'\n",
    "head = 'photo/'\n",
    "num = 0\n",
    "headers = { 'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.90 Safari/537.36',\n",
    "            'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3',\n",
    "           'accept-language':'zh-CN,zh;q=0.9', \n",
    "           'Connection': 'keep-alive'\n",
    "          }#头部\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义爬虫函数\n",
    "def spider(page):\n",
    "    print('创建成功',page)\n",
    "    #定义爬取网页和头部\n",
    "    url_1 = 'http://uuuurt.com'\n",
    "    url_2 = '.html'\n",
    "    head = 'photo/'\n",
    "    num = 0\n",
    "    headers = { 'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.90 Safari/537.36',\n",
    "            'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3',\n",
    "           'accept-language':'zh-CN,zh;q=0.9', \n",
    "           'Connection': 'keep-alive',\n",
    "           'cookie':'Hm_lvt_d48c26f37d31dfa38a27014565968189=1562930842,1562931782,1563155701; Hm_lpvt_d48c26f37d31dfa38a27014565968189=1563155728'\n",
    "          }#头部\n",
    "    for i in range(68):\n",
    "        pag = page + i\n",
    "        url = url_1 + '/Article/shenying/List_' + str(pag) + url_2\n",
    "        response = requests.get(url,headers=headers)\n",
    "        html = response.content\n",
    "        soup = BeautifulSoup(html,'html.parser')\n",
    "        pic = soup.find_all(attrs={'class': 'x'})\n",
    "        flag = 0\n",
    "        print(pag,url,i,'进入主页')\n",
    "        for p in pic:\n",
    "            if p.find('img') == None:\n",
    "                continue\n",
    "#             if flag > 2:\n",
    "#                 break\n",
    "            url_p = p['href']  \n",
    "            for pg in range(20):\n",
    "                l = len(str(url_p))\n",
    "                url_p_1 = url_p[0:l-5]\n",
    "                if pg !=0:\n",
    "                    url_pic = url_1 + url_p_1 + '_' + str(pg+1) + '.html'\n",
    "                else:\n",
    "                    url_pic = url_1 + url_p\n",
    "                print(url_pic,pg,'进入内容')\n",
    "                response = requests.get(url_pic,headers=headers)\n",
    "                html = response.content\n",
    "                soup = BeautifulSoup(html,'html.parser')\n",
    "                try:\n",
    "                    img_list = soup.find_all('img' )\n",
    "                    img = img_list[4]\n",
    "                except:\n",
    "                    pass\n",
    "                else:\n",
    "                    url_img = url_1 + img['src']\n",
    "                    print(url_img)\n",
    "                    try:    \n",
    "                        res = requests.get(url_img,headers = headers)\n",
    "                    except:\n",
    "                        print(url_img,'erro')\n",
    "                        pass\n",
    "                    else:\n",
    "                        path = head + str(page) + '_' + str(num) + '.png'\n",
    "                        f = open(path,'wb') \n",
    "                        for byte in res:\n",
    "                            f.write(byte)\n",
    "                        num += 1\n",
    "                        f.close()\n",
    "#             flag += 1\n",
    "    print('finish')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建 4个线程\n",
    "thrs= []\n",
    "# for i in range(4):\n",
    "#     thrs.append(threading.Thread(target=spider, args=[100*i]) )\n",
    "# # 开始执行线程\n",
    "# [thr.start() for thr in thrs]\n",
    "# # 等待线程结束\n",
    "# [thr.join() for thr in thrs]\n",
    "# print('all_finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spider(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建4个进程(juoyternotebook 中无法开多进程)\n",
    "def time():\n",
    "    print(0)\n",
    "p = Pool()\n",
    "for i in range(4):\n",
    "    p.apply_async(time)\n",
    "p.close()\n",
    "p.join()\n",
    "print('all_finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Queue, Process, Pool\n",
    "import os\n",
    "def test():\n",
    "    time.sleep(2)\n",
    "    print('this is process {}'.format(os.getpid()))\n",
    "\n",
    "def get_pool(n=5):\n",
    "    p = Pool(n) # 设置进程池的大小\n",
    "    for i in range(10):\n",
    "        p.apply_async(test)\n",
    "    p.close() # 关闭进程池\n",
    "    p.join()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    get_pool()\n",
    "    print('ths process is ended')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#爬取文件中url\n",
    "file = '/urls.txt'\n",
    "num = 0\n",
    "head = 'photo/'\n",
    "# f_url = open(file)\n",
    "# urls = f_url.readlines()\n",
    "# for url in urls:\n",
    "#     if 'imgur' in url:\n",
    "#         continue\n",
    "#     try :\n",
    "#         photo = requests.get(url,headers=headers,verify='/tmp/ssl/requests_test.crt')\n",
    "#     except:\n",
    "#         print(url,'can\\'t connect')\n",
    "#     else:\n",
    "#         print(url)\n",
    "#         path = head + str(num) + '.png'\n",
    "#         f = open(path,'wb')\n",
    "#         for byte in photo:\n",
    "#             f.write(byte)\n",
    "#         num += 1\n",
    "# f.close()\n",
    "# f_url.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<img alt=\"\" border=\"0\" hspace=\"0\" onload=\"javascript:resizepic(this)\" onmousewheel=\"return bbimg(this)\" src=\"/200709/20070905234914914.jpg\"/>\n"
     ]
    }
   ],
   "source": [
    "url = 'http://uuuurt.com/Article/shenying/200709/172.html'\n",
    "html = requests.get(url,headers = headers)\n",
    "soup =  BeautifulSoup(html.content,'html.parser')\n",
    "pic = soup.find_all('td',align = 'middle' )\n",
    "for p in pic:\n",
    "    a = p.find('img')\n",
    "    if a and 'gif' not in a['src']:\n",
    "        print(a)\n",
    "# for i in pic:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://googl_2.html\n"
     ]
    }
   ],
   "source": [
    "url_p = 'https://google.com'\n",
    "pg = 0\n",
    "l = len(str(url_p))\n",
    "url_p_1 = url_p[0:l-5]\n",
    "url_p = url_p_1 + '_' + str(pg+2) + '.html'\n",
    "print(url_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#筛选出可以使用的图片\n",
    "import os  \n",
    "from PIL import Image\n",
    "path = 'clothes'\n",
    "files = os.listdir(path)\n",
    "# print(files)\n",
    "for pic in files:\n",
    "    png = path + '/' + pic\n",
    "    try:\n",
    "        img = Image.open(png)\n",
    "    except:\n",
    "        img.close()\n",
    "#         print(pic)\n",
    "        os.remove(png)\n",
    "    else:\n",
    "        img.close()       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
